---
title: "Quality control for RNAseq"
date: "`r Sys.Date()`"
author: "Kat Moore and Evert Bodriesz"
output: 
  html_document:
    toc: yes
    toc_float: yes
    toc_depth: 4
    highlight: kate
    df_print: paged
params:
  tx: "data/rnaseq/interim/01_tx.Rds"
  rnaMeta: "data/rnaseq/metadata/01_rnaMeta.Rds"
  alignstats: "results/rnaseq/multiqc_report_data/multiqc_general_stats.txt"
  or_sum: "results/rnaseq/multiqc_report_data/mqc_fastqc_overrepresented_sequences_plot_1.txt"
  fastqcr: "data/rnaseq/interim/02_fastqcr.Rds"
  min_lib_size: 10^6.7
  mapping_threshold: 75
  or_seq_max: 5
  cor_min: 0.9
---

```{r libraries}
library(here)
library(DESeq2)
library(fastqcr)
library(ggbeeswarm)
library(tidyverse)
library(ggrepel)
library(viridis)
library(ggthemes)
theme_set(theme_bw())

source(here("src/rnaseq/fastqcr_utils.R"))
```

Quality control via multiqc and fastqcr.

## Quality criteria

Samples will be excluded if:

* Library size less than `r params$min_lib_size`
* Less than `r params$mapping_threshold` of reads mapped
* Overrepresented sequences greater than `r params$or_seq_max`%
* GC module flagged as FAIL
* For duplicates, correlation less than `r params$cor_min`

## Load data

Data was packaged into a list via tx_import in the previous notebooks (01_process_metadata_tximport.Rmd)

```{r}
tx <- readRDS(here(params$tx))

rnaMeta<- readRDS(here(params$rnaMeta))
```

Multiqc summary

```{r}
multiqc <- read_tsv(file=here(params$alignstats), show_col_types = F)

colnames(multiqc) <- str_remove(colnames(multiqc), "Salmon_|FastQC_") %>%
  str_remove(., "mqc-generalstats-") %>%
  str_remove(., "salmon-|fastqc-")

multiqc <- multiqc %>% rename(fastq = Sample)

head(multiqc)
```

Fastqcr aggregation

```{r}
# Don't rename the sample column until later, doing so breaks some functions
qc <- readRDS(here(params$fastqcr))
head(qc)
```

## Batch overview

Sequencing batch overview. Most NAs refer to samples that were sequenced more than once, in which case the batch is omitted from the second entry.

```{r}
rnaMeta %>% group_by(batch) %>% count()
```

## Library size

RMarkdown params expressed as exponents are interpreted as characters. They cannot directly be converted to the correct class. We therefore must manually set this parameter.

```{r}
params$min_lib_size
min_lib_size <- 10^6.7
```


We previously set a minimum library size of `r params$min_lib_size`(`r 10^6.7`). Based on the histogram, we get the following distribution.

```{r}
hist(log10(colSums(tx$counts)), breaks=40, main="Log10 library size PPBC") 
abline(v = log10(min_lib_size), col = "red")
```

Record library size and mark samples below the threshold

```{r}
multiqc <- colSums(tx$counts) %>%
  enframe("fastq", "lib.size") %>%
  mutate(low_count_sample = lib.size < min_lib_size) %>%
  mutate(fastq = str_remove(fastq, ".fastq.gz")) %>%
  left_join(., multiqc, by = "fastq")

multiqc %>%
  filter(low_count_sample)
```

## Alignment stats

The majority of samples with poor mapping are below the library size cutoff. 

```{r}
multiqc %>% ggplot(aes(x=lib.size, y=percent_mapped, color=low_count_sample)) +
  geom_point() + scale_x_log10() +
  ggtitle("Poor mapping is associated with small library size") +
  geom_hline(yintercept = 75, color="black", linetype = "dashed")
```

Add a threshold of `r params$mapping_threshold`` mapped reads.

```{r}
multiqc <- multiqc %>%
  mutate(poor_mapping = percent_mapped < params$mapping_threshold,
           .after = percent_mapped)

multiqc %>%
  filter(poor_mapping)
```

Add multiqc results to metadata.

```{r}
sample_annot <- multiqc %>%
  mutate(fastq = paste0(fastq, ".fastq.gz")) %>%
  select(fastq:poor_mapping) %>%
  full_join(rnaMeta, ., by = "fastq")
```

## Fastqcr

Be aware that Fastqcr reads all fastq samples into its summary, including those which have been pre-excluded based on clinical reasons. Custom reporting functions used in this notebook do exclude those samples.

```{r}
summary(qc)
```

### Plot overview

```{r}
qc %>% ggplot(aes(x=module, fill = status)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 90))
```

### Per base sequence content

```{r}
summary(qc) %>% filter(module == "Per base sequence content")
```

Per base sequence content is almost always a fail in RNAseq libraries, as per this excerpt from the fastqc documentation. Multiqc confirms the bias is largely at the start of the reads.

"It's worth noting that some types of library will always produce biased sequence composition, normally at the start of the read. Libraries produced by priming using random hexamers (including nearly all RNA-Seq libraries) and those which were fragmented using transposases inherit an intrinsic bias in the positions at which reads start. This bias does not concern an absolute sequence, but instead provides enrichement of a number of different K-mers at the 5' end of the reads. Whilst this is a true technical bias, it isn't something which can be corrected by trimming and in most cases doesn't seem to adversely affect the downstream analysis."

### Per tile sequence quality

```{r}
summary(qc) %>% filter(module == "Per tile sequence quality")
```

Per tile sequence quality is not reported by Multiqc and is therefore harder to visually inspect. From the documentation: 

This graph will only appear in your analysis results if you're using an Illumina library which retains its original sequence identifiers. Encoded in these is the flowcell tile from which each read came. The graph allows you to look at the quality scores from each tile across all of your bases to see if there was a loss in quality associated with only one part of the flowcell. Reasons for seeing warnings or errors on this plot could be transient problems such as bubbles going through the flowcell, or they could be more permanent problems such as smudges on the flowcell or debris inside the flowcell lane. Whilst warnings in this module can be triggered by individual specific events we have also observed that greater variation in the phred scores attributed to tiles can also appear when a flowcell is generally overloaded. In this case events appear all over the flowcell rather than being confined to a specific area or range of cycles. We would generally ignore errors which mildly affected a small number of tiles for only 1 or 2 cycles, but would pursue larger effects which showed high deviation in scores, or which persisted for several cycles. 

Is there a particular batch with worse sequence quality?

```{r}
as.data.frame(qc) %>% filter(module=="Per tile sequence quality") %>%
  mutate(sample = paste0(sample, ".fastq.gz")) %>%
  dplyr::rename(per_tile_sequence_quality = status) %>%
  left_join(.,sample_annot, by=c("sample"="fastq")) %>%
  ggplot(aes(x=batch, y=lib.size, color=per_tile_sequence_quality)) +
  ggbeeswarm::geom_beeswarm() +
  ggtitle("Per tile sequence quality by batch")
```



```{r}
sample_annot <- add_qc_to_metadata(sample_annot, qc, "Per tile sequence quality")
```

### Sequence duplication levels

Overwhelmingly the samples fail this module.

```{r}
summary(qc) %>% filter(module == "Sequence Duplication Levels")
```

The 10 samples that pass sequence duplication levels are those with tiny library sizes. All samples above the library size cutoff fail this module.

```{r}
qc %>% filter(module == "Sequence Duplication Levels") %>% ggplot(aes(x=status,y=as.integer(tot.seq))) +
  geom_boxplot() + scale_y_log10() + geom_hline(yintercept = 10^6.7, color="red") +
  ylab("Library size") + xlab("Sequence duplication level") +
  ggtitle("Samples above the lib.size cutoff are flagged for sequence duplication level")
```

Add the information to the sample annotation data for bookkeeping.

```{r}
sample_annot <- add_qc_to_metadata(sample_annot, qc, "Sequence Duplication Levels")
```

### Duplication by sample

What's the distribution of the samples which pass the library size threshold?

```{r, echo=F}
seqdup <- retrieve_fastqc_module(qc, sample_annot, module="Sequence Duplication Levels")
```

Plot duplication levels by sample

```{r}
seqdup %>% rename(dup_level = `Duplication Level`,
                  perc_total = `Percentage of total`) %>%
  filter(!is.na(study_group)) %>%
  ggplot(aes(x=factor(dup_level, levels=c("1","2","3","4","5","6","7","8","9",">10",">50",">100",">500",">1k",">5k",">10k+")),
             y = perc_total, color = study_group, group=sample)) + geom_line() +
  xlab("Sequence duplication levels") + ylab("Percentage of total") +
  scale_color_viridis_d()#+ theme(legend.position = "none")
```

All samples have high sequence duplication: probably this has to do with the ffpe preparation in combination with the rRNA library prep. Given that most samples within our dataset have this issue, we don't have a reasonable cutoff to use for this metric.

### Duplication by batch

It doesn't appear that one batch or the other has a higher duplication level than the rest.

```{r}
seqdup %>% rename(dup_level = `Duplication Level`, perc_total = `Percentage of total`) %>%
  filter(!is.na(batch)) %>%
  ggplot(aes(x=factor(dup_level, levels=c("1","2","3","4","5","6","7","8","9",">10",">50",">100",">500",">1k",">5k",">10k+")),
             y = perc_total, fill = batch, group=batch)) + geom_bar(stat="identity") +
  xlab("Sequence duplication levels") + ylab("Cumulative percent reads") +
  scale_fill_viridis_d()
```

## Overrepresented sequences

Warnings are prevalent for this module.

```{r}
summary(qc) %>% filter(module=="Overrepresented sequences")
```

Add the module status to sample annotation for bookkeeping.

```{r}
sample_annot <- add_qc_to_metadata(sample_annot, qc, "Overrepresented sequences")
```

### Lib.size and overrepresented sequences

Is there a connection between overrepresented sequences and library size?

```{r}
qc %>% filter(module == "Overrepresented sequences") %>%
  ggplot(aes(x=status,y=as.integer(tot.seq))) +
  geom_boxplot() +
  scale_y_log10() +
  geom_hline(yintercept = min_lib_size, color="red") +
  ggtitle("Library size vs overrepresented sequences")
```

### Threshold for overrepresented sequences

Multiqc has a report which can summarize this for us.

```{r}
or_summary <- read_tsv(here(params$or_sum), show_col_types = F,
                       name_repair = "universal")
or_summary <- or_summary %>%
  mutate(percent_overrepresented_sequences = Top.over.represented.sequence +
           Sum.of.remaining.over.represented.sequences) %>%
  mutate(fastq = paste0(Sample, ".fastq.gz"))

sample_annot <- left_join(sample_annot,
                          select(or_summary, fastq,
                                 percent_overrepresented_sequences),
                          by="fastq")
```

Graph this percentage for all samples.

```{r}
sample_annot %>%
  ggplot(aes(x=lib.size, y=percent_overrepresented_sequences, color=low_count_sample)) +
  geom_point() + scale_x_log10() +
  ggtitle("Extremely high % overrepresented sequences occurs with small library size")
```

Graph those which are above the lib.size threshold.

```{r}
sample_annot %>% filter(low_count_sample==FALSE) %>%
  ggplot(aes(x=study_group, y=percent_overrepresented_sequences)) +
  geom_boxplot() + geom_hline(yintercept = params$or_seq_max, color="red", linetype = "dashed") +
  ggtitle(paste0("Overrepresented sequences by study group with ",
                 params$or_seq_max, "% threshold"))
```

Mark those samples with over `r params$or_seq_max`% total overrepresented sequences for exclusion.  

```{r}
sample_annot <- sample_annot %>%
  mutate(too_high_overrepresented_seq = percent_overrepresented_sequences >
           params$or_seq_max)
```
  
Which additional samples do we lose, after filtering on library size?

```{r}
sample_annot %>%
  filter(low_count_sample != TRUE) %>%
  select(study_group, too_high_overrepresented_seq) %>% table()
```


## Percent GC content

From the documentation:

This module measures the GC content across the whole length of each sequence in a file and compares it to a modelled normal distribution of GC content. In a normal random library you would expect to see a roughly normal distribution of GC content where the central peak corresponds to the overall GC content of the underlying genome. Since we don't know the the GC content of the genome the modal GC content is calculated from the observed data and used to build a reference distribution. An unusually shaped distribution could indicate a contaminated library or some other kinds of biased subset. A normal distribution which is shifted indicates some systematic bias which is independent of base position. If there is a systematic bias which creates a shifted normal distribution then this won't be flagged as an error by the module since it doesn't know what your genome's GC content should be.

Warnings in this module usually indicate a problem with the library. Sharp peaks on an otherwise smooth distribution are normally the result of a specific contaminant (adapter dimers for example), which may well be picked up by the overrepresented sequences module. Broader peaks may represent contamination with a different species. 

It is also well known that rRNA contamination can lead to large shifts in GC content peaks.

Warnings are common here, with a few failures. These failures may be among the pre-excluded samples.

```{r}
summary(qc) %>%
  filter(module == "Per sequence GC content")
```

Add module data to sample annotation for bookkeeping.

```{r}
sample_annot <- add_qc_to_metadata(sample_annot, qc, "Per sequence GC content")
```

Which samples are flagged as failing the GC content module?

```{r}
failed_gc <- summary(qc) %>%
  filter(module == "Per sequence GC content") %>% pull(failed) %>%
  str_split(., ", ") %>% unlist() %>% paste0(., ".fastq.gz")
#pre-excluded samples only
filter(sample_annot, fastq %in% failed_gc)
```

Do the sequences flagged for GC content fail some of the other quality metrics?

```{r}
sample_annot %>% filter(low_count_sample==FALSE) %>% 
  ggplot(aes(x=per_tile_sequence_quality, y=percent_overrepresented_sequences, color=per_sequence_gc_content)) +
  ggbeeswarm::geom_quasirandom()
```

To reduce the risk of PCR artefacts and unusual contaminants, we will exclude samples that fail this module. 

## Correlation analysis on duplicate samples

Several samples have duplicate runs. For those with duplicates, we want to ensure that the duplicates correlate better to each other than they do to random patients. If they do, we combine the replicates. If the correlation is poor, then discard the older of the two samples.

```{r}
duplicate_patients <-
  sample_annot %>% 
  group_by(patient_ID) %>%
  summarise(N = n()) %>%
  filter(N >= 2) %>%
  pull(patient_ID)

duplicate_patients
```


```{r Get correlations}
get_correlations_for_patient_samples <- function(pref, sannot = sample_annot){
  stopifnot(pref %in% c(sannot$patient_ID, "random"))
  if (pref %in% sannot$patient_ID) {
    cors <- cor(
      tx$counts[, filter(sannot, patient_ID %in% pref)$fastq],
      method = "spearman"
      ) 
  } else{
    samples <- sample(sannot$fastq, 2)
    cors <- cor(tx$counts[, samples], method = "spearman")
  }
  
  cors[lower.tri(cors, diag = T)] <- NA
  cors %>%
    as_tibble(rownames = "sample_1") %>%
    gather(sample_2, spearman, -sample_1) %>%
    filter(!is.na(spearman)) %>%
    mutate(patient_ID = pref) %>%
    select(patient_ID, sample_1, sample_2, spearman)
}

correlations <-
  purrr::map(duplicate_patients, get_correlations_for_patient_samples) %>%
  bind_rows()

correlations %>% head()
```

Also look at random correlations as a point of comparison.
We (correctly) suspect that low correlations between repeat sequencing runs from the same patient is due to one library size being much smaller than the other.

```{r}
correlations_random <- 
  purrr::map(rep("random", 100), get_correlations_for_patient_samples) %>% 
  bind_rows() 

ggplot(
  #Retrieve flags for first sample
  left_join(bind_rows(correlations, correlations_random),
            select(sample_annot, sample_1 = fastq,
                   #Potential color metrics
                   lib.size, 
                   #poor_mapping,
                   low_count_sample,
                   #high_dup_sample, too_high_overrepresented_sequences
                   ),
            by = "sample_1") %>%
    #And again for second
    left_join(.,
            select(sample_annot, sample_2 = fastq,
                   #Potential color metrics
                   lib.size, 
                   low_count_sample, 
                   #poor_mapping,
                   #high_dup_sample, too_high_overrepresented_sequences
                   ),
            by = "sample_2") %>%
    mutate(
      low_count_samples = as.factor(low_count_sample.x + low_count_sample.y),
      lib.size.ave = (lib.size.x + lib.size.y)/2
    ),
  aes(x = !(patient_ID == "random"), y = spearman,
      color = low_count_samples,
      #size = lib.size.ave
      )) +
  ggbeeswarm::geom_quasirandom() +
  labs(title = "Correlation in readcounts (all samples)",
       x = "Samples from same patient?",
       y = "Spearman correlation between samples") #+
  #geom_hline(yintercept = 0.9, color="red")
```

And if we eliminate those which don't fail one of the other flags?

```{r}
good_libs <- sample_annot %>%
  filter(low_count_sample == F) %>%
  filter(poor_mapping == F) %>%
  filter(too_high_overrepresented_seq == F)

dup_pref_good_lib <-
  good_libs %>% 
  group_by(patient_ID) %>%
  summarise(N = n()) %>%
  filter(N >= 2) %>%
  pull(patient_ID)

corrs_good_libs <- 
  purrr::map(.x = dup_pref_good_lib,
             sannot = good_libs,
             get_correlations_for_patient_samples) %>% 
  bind_rows()

corrs_random_good_libs <- 
  purrr::map(.x = rep("random", 100),
             sannot = good_libs,
             get_correlations_for_patient_samples) %>% 
  bind_rows() 

ggplot(
  bind_rows(corrs_good_libs, corrs_random_good_libs),
  aes(x = !(patient_ID == "random"), y = spearman)) +
  ggbeeswarm::geom_quasirandom() +
  labs(title = "Correlation in readcounts (no flags)",
       x = "Samples from same patient?",
       y = "Spearman correlation between samples") +
  geom_hline(yintercept = params$cor_min, color = "red", linetype = "dashed")

```

From this we can see that when the library prep otherwise goes well, most samples sequenced from the same patient have a correlation of above 0.9.
Random patients are also correlated, but not quite as highly.

Identify duplicate patients below the threshold of `r params$cor_min`.

```{r Low correlation patients}
low_correlation_patients <- 
  correlations %>% 
  filter(patient_ID %in% pull(filter(correlations, spearman < params$cor_min),
                              patient_ID)) %>% 
  arrange(patient_ID)

low_correlation_patients %>%
  relocate(spearman, .before = everything())
```

Examine other flags for low correlation patients.

```{r}
low_correlation_patients <- low_correlation_patients %>% 
  pivot_longer(cols = c("sample_1", "sample_2"), values_to = "fastq") %>%
  left_join(., sample_annot %>% select(fastq, lib.size:per_sequence_gc_content),
            by = "fastq")

low_correlation_patients
```

Discard the sample that failed the low count threshold. 

```{r Low correlation samples}
low_correlation_samples <- 
  low_correlation_patients %>% 
  filter(low_count_sample) %>% 
  pull(fastq)

print(paste("Total of",length(low_correlation_samples),
           "low correlation samples will be discarded."))
```

Add duplicate and correlation status to sample annotation

```{r}
sample_annot <- sample_annot %>%
  mutate(
    duplicate = duplicated(sample_annot$patient_ID) |
                           duplicated(sample_annot$patient_ID, fromLast = T))

sample_annot <- sample_annot %>%
  mutate(low_correlation_sample = fastq %in% low_correlation_samples)

sample_annot %>% select(duplicate, low_correlation_sample) %>% table()
```

## Exclude failed samples

* Library size less than `r params$min_lib_size`
* Less than `r params$mapping_threshold` of reads mapped
* Overrepresented sequences greater than `r params$or_seq_max`%
* GC module flagged as FAIL
* For duplicates, correlation less than `r params$cor_min`

Remove samples which fail one or more of these criteria.

```{r}
sample_annot_filtered <- sample_annot %>%
  filter(low_count_sample == FALSE &
           poor_mapping == FALSE &
           too_high_overrepresented_seq == FALSE &
           per_sequence_gc_content!="FAIL" & 
           low_correlation_sample == FALSE)
```

```{r}
print(paste("Discarded", nrow(sample_annot) - nrow(sample_annot_filtered),
            "samples out of", nrow(sample_annot), "during QC.",
            nrow(sample_annot_filtered), "remaining."))
```

```{r}
sample_annot <- sample_annot %>%
  mutate(keep = fastq %in% sample_annot_filtered$fastq) %>%
  select(patient_ID, keep, fastq, everything()) %>%
  arrange(patient_ID)

head(sample_annot)
```

### Summary discarded samples

```{r}
discarded_df <- sample_annot %>%
  filter(keep == F)

discarded_df <- discarded_df %>%
  select(fastq, sample_name, patient_ID,
         low_count_sample, poor_mapping, too_high_overrepresented_seq,
         low_correlation_sample, per_sequence_gc_content, everything())
discarded_df
```

```{r}
patients_discarded <- setdiff(unique(discarded_df$patient_ID),
                              unique(sample_annot_filtered$patient_ID))
summary_discarded_samples <- discarded_df %>%
  summarise(total_samples_discarded=nrow(discarded_df),
            total_patients_discarded=length(patients_discarded),
            total_low_count = sum(low_count_sample==T),
            total_poor_mapping = sum(poor_mapping ==T),
            total_low_cor = sum(low_correlation_sample==T),
            total_gc_fail = sum(per_sequence_gc_content=="FAIL")
            )

summary_discarded_samples <- summary_discarded_samples %>% t() %>%
  as.data.frame() %>% rename(count=V1)

summary_discarded_samples
```

Write discarded samples

```{r}
write_csv(discarded_df,
          path=here("data/rnaseq/metadata/02_discarded_samples.csv"))
```

Difference in study group and clinical subtype after filtering:

```{r}
(sample_annot_filtered %>%
   select(study_group, clin_subtype) %>% table() %>% as.matrix())-
  (sample_annot %>% select(study_group, clin_subtype) %>%
     table() %>% as.matrix())
```

Write new metadata:

```{r}
stopifnot(all(sample_annot_filtered$fastq %in% filter(sample_annot, keep == T)$fastq))
saveRDS(sample_annot_filtered,
        here("data/rnaseq/interim/02_sample_annot_filtered.Rds"))
```

## Filter count data

```{r}
subset_tximport <- function(txi, cols){
  lapply(txi, function(x) if ( is.matrix(x) ) return(x[, cols]) else return(x))
}

tx_clean <- subset_tximport(tx, sample_annot_filtered$fastq)
```

Save filtered count matrix

```{r}
saveRDS(tx_clean, file = here("data/rnaseq/interim/02_tx_clean.Rds"))
```

## Session info

```{r}
sessionInfo()
```
